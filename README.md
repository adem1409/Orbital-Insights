# ğŸš€ Orbital Insights

**Orbital Insights** is a data warehouse and business intelligence project built around satellites launch data. It models real-world satellites and rockest information using a star schema, automates the ETL process with Python, and visualizes insights through Metabase dashboards.

## ğŸ“Š Project Overview

This project transforms raw satellite, rocket, and launch data into an analytical data warehouse hosted on PostgreSQL. It provides KPIs such as:

- Most reliable rockets based on success rate
- Country contributions to satellite launches
- Rocket efficiency by thrust-to-payload ratio
- Satellite launch trends over time

## ğŸ§° Tech Stack

- **Python** â€” ETL scripts (pandas + psycopg2)
- **PostgreSQL** â€” Star schema data warehouse
- **Docker** â€” Containerized database setup

## ğŸ§± Data Warehouse Design

The schema is designed using a **factless fact table** to handle the many-to-many relationship between satellites and launches. It includes:

- `dim_satellite`
- `dim_rocket`
- `dim_launch`
- `dim_launch_site`
- `dim_date`
- `fact_satellite_launch`

![star_schema](https://github.com/user-attachments/assets/77f4a7da-84f5-4efd-976a-0ff11a3dc908)


## âš™ï¸ ETL Automation

ğŸ” 1. Extract

Source data comes from three CSV files:

launches.csv â€“ launch details (status, provider, mission, site, etc.)

rockets.csv â€“ technical specs and metadata for rockets

satellites.csv â€“ information about satellites and their orbits

Data is read into pandas DataFrames for initial inspection and cleansing.


ğŸ§ª 2. Transform

ğŸ“… Date Formatting
All date fields (e.g. date, date_of_launch) are converted to proper datetime objects.
These dates are then broken into year, month, and day to populate the dim_date dimension.

â“ Handling Missing Values
Missing values are filled when possible using domain logic or calculated estimates:
orbit_period is estimated using a formula based on orbit class and altitude when missing.

ğŸŒ Country Name Standardization
Country names are standardized across datasets using a reference mapping (e.g., 'USA' â†’ 'United States', 'UK' â†’ 'United Kingdom').
Arrays of country fields (country_of_operator, country_of_contractor) are also cleaned and deduplicated.

ğŸš€ Rocket Name Normalization (Fuzzy Matching)
Rocket names across the launches and satellites datasets often have inconsistent naming.
Fuzzy matching (using fuzzywuzzy) is applied to align these names to a canonical list from rockets.csv.

ğŸ§© Building the Fact Table
The cleaned and merged data is used to assign foreign keys from all dimension tables.
Each row in the fact table (fact_satellite_launch) is a unique combination of date, launch, satellite, rocket, and launch site â€” without any direct measure, forming a factless fact table.


ğŸ›¢ï¸ 3. Load

Data is loaded into a PostgreSQL data warehouse using psycopg2 and parameterized SQL queries.

Dimension tables are inserted with ON CONFLICT DO NOTHING to avoid duplicates.

Fact table entries are inserted only after all foreign key lookups succeed.
